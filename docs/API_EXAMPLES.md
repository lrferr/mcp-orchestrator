# MCP Orchestrator API - Data & Ollama Examples

## 1. Querying Databases via MCP

Depois de conectar um servidor MCP (`POST /api/mcp/oracle-monitor/connect`), voc√™ pode enviar uma query:

```bash
POST /api/mcp/query?prompt=retorne os 5 primeiros registros da tabela frota.motorista
```

**Resposta t√≠pica:**

```json
{
  "prompt": "retorne os 5 primeiros registros da tabela frota.motorista",
  "response": "## ‚úÖ Query Executed Successfully\n\n**Database**: oracle\n**SQL**: ```SELECT * FROM frota.motorista WHERE ROWNUM <= 5```\n\n{\n  \"rows\": [\n    { \"ID_MOTORISTA\": 174, \"APELIDO\": \"Kassab\" },\n    { \"ID_MOTORISTA\": 175, \"APELIDO\": \"Silva\" }\n  ],\n  \"metadata\": { \"count\": 2 }\n}"
}
```

## 2. Ollama Integration Module

O projeto inclui endpoints para verificar e listar modelos dispon√≠veis no Ollama.

> **üìö Complete Documentation:** See [API_ENDPOINTS.md](API_ENDPOINTS.md) for full API documentation.

### Endpoints Adicionados:

#### 2.1 **Listar Modelos do Ollama**
```
GET /api/mcp/ollama/models
```

**Exemplo de resposta:**
```json
{
  "total": 3,
  "models": [
    {
      "name": "llama3:latest",
      "size": 4808364084,
      "modifiedAt": "2024-01-15T10:30:00.000Z",
      "format": "gguf",
      "family": "llama3",
      "parameterSize": "8B",
      "quantizationLevel": "Q4_0"
    },
    {
      "name": "mistral:7b",
      "size": 4214570084,
      "modifiedAt": "2024-01-10T08:45:00.000Z",
      "format": "gguf",
      "family": "mistral",
      "parameterSize": "7B",
      "quantizationLevel": "Q4_0"
    }
  ]
}
```

#### 2.2 **Obter Informa√ß√µes Detalhadas sobre um Modelo Espec√≠fico**
```
GET /api/mcp/ollama/models/{modelName}
```

**Exemplo:**
```
GET /api/mcp/ollama/models/llama3:latest
```

**Exemplo de resposta:**
```json
{
  "model": {
    "name": "llama3:latest",
    "size": 4808364084,
    "modifiedAt": "2024-01-15T10:30:00.000Z",
    "format": "gguf",
    "family": "llama3",
    "parameterSize": "8B",
    "quantizationLevel": "Q4_0",
    "template": "{{ if .System }}<|start_header_id|>system<|end_header_id|>\n{{ .System }}<|eot_id|>",
    "parameters": "num_predict 50 temperature 0.4 top_k 40 top_p 0.9"
  }
}
```

#### 2.3 **Testar Conex√£o com Ollama**
```
GET /api/mcp/ollama/test-connection
```

**Exemplo de resposta (sucesso):**
```json
{
  "status": "SUCCESS",
  "baseUrl": "http://localhost:11434",
  "message": "Connection to Ollama successful"
}
```

**Exemplo de resposta (erro):**
```json
{
  "status": "ERROR",
  "baseUrl": "http://localhost:11434",
  "message": "Failed to connect to Ollama: Connection refused"
}
```

## Como Usar no Swagger UI

1. **Acesse o Swagger UI**: `http://localhost:8080/swagger-ui.html`
2. **Navegue at√© a se√ß√£o "McpApi"**
3. **Encontre os endpoints "ollama" para intera√ß√£o com modelos**
4. **Use o bot√£o "Try it out" para testar os endpoints**

## Configura√ß√£o

O Ollama application properties j√° est√° configurado no `application.properties`:

```properties
# Configura√ß√£o do Ollama
spring.ai.ollama.base-url=http://localhost:11434/
spring.ai.ollama.chat.model=llama3
```

## Arquitetura

O novo m√≥dulo inclui:

1. **`OllamaService.java`** - Servi√ßo para intera√ß√£o com API do Ollama
2. **Endpoints atualizados no `McpServerController.java`** para integra√ß√£o com Ollama
3. **Tratamento de exce√ß√µes completo** para cen√°rios offline/disconectado do Ollama
4. **Mapeamento detalhado** de informa√ß√µes dos modelos (tamanho, formato, fam√≠lia, etc.)

## Benef√≠cios

- ‚úÖ **Verifica√ß√£o r√°pida** dos modelos dispon√≠veis via API
- ‚úÖ **Informa√ß√µes detalhadas** sobre cada modelo
- ‚úÖ **Monitoramento da conex√£o** com o servidor Ollama
- ‚úÖ **Integra√ß√£o direta** com a API REST existente no Swagger UI
- ‚úÖ **Tratamento de erros robusto** quando Ollama n√£o est√° dispon√≠vel
